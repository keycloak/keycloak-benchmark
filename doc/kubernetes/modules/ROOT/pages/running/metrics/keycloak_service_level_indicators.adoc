= {project_name} Service Level Indicators
:description: This document contains details of the SLI's to monitor your {project_name} deployment's performance.

Service Level Objectives (SLOs) and Service Level Indicators (SLIs) are essential components in monitoring and maintaining the performance and reliability of {project_name} in production environments.

- **SLOs** define the target performance or reliability level that {project_name} should achieve, such as availability or response times.
- **SLIs** are the specific metrics used to measure how well {project_name} is meeting these targets, such as uptime percentage or request latency.

By tracking these, {project_name}
users can ensure that their deployments are running optimally and detect potential issues early.
These metrics are also invaluable for teams supporting {project_name},
enabling effective troubleshooting and performance tuning.

We assume that the scenario
for defining the SLOs and SLIs is based on the below steps and also the histogram metrics are enabled in {project_name} for the PromQL queries
to run as intended.

====
As a {project_name} user,

* I want to be able to log in,
* refresh my token,
* and log out.

So that I can interact with the {project_name} system effectively and perform the necessary tasks without interruption.
====


[cols="2,1,2,2", options="header"]
|===
| Service Level Objective^*^ | Service Level Indicator | SLI Metric         | Metric Details

| {project_name} should be available 99.99% of the time.                 | Availability            | Uptime percentage is the ratio of successful authentication requests to total authentication requests.               |
The `up` metric which indicates if the Prometheus server is able to scrape metrics from the {project_name} instance.
This metric will have a value of 1 if the {project_name} service is available
and responding to Prometheus scrape requests,
and 0 if the service is down or unreachable.

It could be represented in a pseudo PromQL query as `sum(up{...}) > 0`

| 95% of {project_name} authentication requests should have a latency below 200ms. | Authentication Latency  | {project_name} server-side metrics to track latency for specific endpoints along with Response Time Distribution.            | `http_server_requests_seconds_bucket`, `http_server_requests_seconds_count`.

https://www.keycloak.org/keycloak-benchmark/kubernetes-guide/latest/running/metrics/keycloak_cluster#processing-time[More details about the metrics are captured here.]

In the next section there is an example PromQL query,
which explains how these metrics can be fetched
and note
that you have
to have working Prometheus server scraping metrics data
from {project_name} metrics endpoint at a given interval.

| The error rate of {project_name} requests should be less than 0.1%.                        | Error Rate | The ratio of failed authentication requests to total requests.                                                       | Failed requests could be identified by the `5xx error codes`
and `4xx error codes` generated by the {project_name} server
and those could be further per URL.

Similar to the previous Latency SLI,
in the next section we provide an example PromQL query to fetch error requests rate.
|===

^*^ These SLO target values are an example and should be tailored to fit your use case and deployment.

== PromQL queries

=== Query for calculating authentication request latency:


[source,plaintext]
----
sum(irate(http_server_requests_seconds_bucket{uri=~"/realms/{realm}/protocol/{protocol}/(token|auth|logout)|/realms/{realm}/login-actions/authenticate", le="0.25", namespace="$namespace", pod="$pod_name"}[2m])) without (le) /
irate(http_server_requests_seconds_count{uri=~"/realms/{realm}/protocol/{protocol}/(token|auth|logout)|/realms/{realm}/login-actions/authenticate", namespace="$namespace", pod="$pod_name"}[2m])
----

==== Query explanation:

This Prometheus query calculates the percentage of authentication requests
that completed within 0.25 seconds relative to all authentication requests for specific Keycloak endpoints,
targeting a particular namespace and pod, over the past 2 minutes.

===== *irate(http_server_requests_seconds_bucket{...}[2m]) without (le)*:
- Computes the instantaneous rate of requests that completed in 0.25 seconds or less for the specified Keycloak endpoints (`token`, `auth`, `logout`, etc.), in the given `namespace` and `pod`, over the last 2 minutes.
- The "without (le)" clause ensures aggregation across all response time buckets.

===== *irate(http_server_requests_seconds_count{...}[2m])*:
- Calculates the instantaneous rate of all requests (successful and failed) for the same Keycloak endpoints, namespace, and pod within the past 2 minutes.

===== *Resulting value from division*:
- Divides the rate of requests completed in <= 0.25 seconds by the total rate of requests, yielding the percentage of authentication requests with a response time under 0.25 seconds.

=== Query to fetch rate of server errors:

[source,plaintext]
----
irate(http_server_requests_seconds_count{uri=~"/realms/{realm}/protocol/{protocol}/(token|auth|logout)|/realms/{realm}/login-actions/authenticate", outcome="SERVER_ERROR"}[2m]) / irate(http_server_requests_seconds_count{uri=~"/realms/{realm}/protocol/{protocol}/(token|auth|logout)|/realms/{realm}/login-actions/authenticate"}[2m])
----

==== Query explanation:

This Prometheus query calculates the proportion of requests that resulted in server side errors (5xx error codes),
relative to all requests (both successful and failed)
for specific Keycloak endpoints, over the past 2 minutes.

===== *irate(http_server_requests_seconds_bucket{...}[2m])*:
- Computes the instantaneous rate of server errors (labeled as SERVER_ERROR),
targeting Keycloak endpoints (token, auth, logout, etc.)
over the last 2 minutes.

===== *irate(http_server_requests_seconds_count{...}[2m])*:
- Calculates the instantaneous rate of all requests (successful and errors) for the same Keycloak
endpoints in the past 2 minutes.

===== *Resulting value from division*:

- Divides the rate of client errors by the total rate of requests
(successful and errors), providing the percentage of server errors.


=== Query to fetch rate of client errors:

[source,plaintext]
----
irate(http_server_requests_seconds_count{uri=~"/realms/{realm}/protocol/{protocol}/(token|auth|logout)|/realms/{realm}/login-actions/authenticate", outcome="CLIENT_ERROR"}[2m]) / irate(http_server_requests_seconds_count{uri=~"/realms/{realm}/protocol/{protocol}/(token|auth|logout)|/realms/{realm}/login-actions/authenticate"}[2m])
----

==== Query explanation:

This Prometheus query calculates the proportion of requests that resulted in client side errors (4xx error codes),
relative to all requests (both successful and failed)
for specific Keycloak endpoints, over the past 2 minutes.

===== *irate(http_server_requests_seconds_bucket{...}[2m])*:
- Computes the instantaneous rate of client errors (labeled as CLIENT_ERROR),
targeting Keycloak endpoints (token, auth, logout, etc.)
over the last 2 minutes.

===== *irate(http_server_requests_seconds_count{...}[2m])*:
- Calculates the instantaneous rate of all requests (successful and errors) for the same Keycloak
endpoints in the past 2 minutes.

===== *Resulting value from division*:

- Divides the rate of client errors by the total rate of requests
(successful and errors), providing the percentage of client errors.
