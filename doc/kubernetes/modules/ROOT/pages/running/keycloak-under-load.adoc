= Running Keycloak under load
:description: This describes configuration tweaks and changes on how to run Keycloak under load.

{description}

== Audience

This guide describes advanced Keycloak configurations for Kubernetes which are load tested and will recover from single Pod failures.

While the Helm charts in the Keycloak Benchmark project mix different aspects of production style deployments with instrumentation and monitoring, this documentation focuses on a minimal deployment with optional add-ons which admins can opt in for their own deployments.

See xref:running/index.adoc[] for additional guides.

== Prerequisites

* OpenShift or Kubernetes cluster running
* Understanding of a https://www.keycloak.org/operator/basic-deployment[Basic Keycloak deployment]

== Procedure

// TODO: Which settings to include in the standard recipe, and which in separate optional steps below

. Determine the sizing of the deployment using xref:benchmark-guide::report/rosa-benchmark-key-results.adoc[].

. https://www.keycloak.org/operator/installation[Deploy Keycloak Operator]

. Deploy the Keycloak CR with the following values:
+
[source,yaml]
----
include::example$helm/keycloak.yaml[tag=keycloak]
----
<1> The database connection pool initial, max and min size should be identical to allow statement caching for the database.
<2> To be able to analyze the system under load, enabling the metrics endpoint is helpful.
The downside of the setting is that, the metrics will be available at the external Keycloak endpoint, so you must add a filter so that the endpoint is not available from the outside.
<3> The internal JGroup thread pools is by default set up for 200 threads maximum.
The number of all Keycloak threads in the stateful set should not exceed the number of JGroup threads to avoid a JGroup thread pool exhaustion which could stall Keycloak request processing.
It might be beneficial to limit the number of threads even further, as too many concurrent threads will lead to throttling by Kubernetes once the requested CPU limit is reached.
<4> By default, Quarkus will queue all incoming requests infinitely.
With this setting, there is maximum queue length.
<5> The JVM options set additional parameters:
* `jgroups.thread_dumps_threshold` ensures that a log message "`thread pool is full`" appears once the JGroup thread pool is full for the first time
* Adjust the memory settings for the heap
<6> During Keycloak Infinispan view updates for members leaving and rebalancing, there is an increased latency for all requests, observed with up to 10 seconds.
With all requests being queued, also the liveness probe is queued, and is therefore slow.
In a high-load or even overload scenario, the probes will be queued in the executor thread pool, and won't return in time.
With load shedding activated, when requests are rejected from the executor thread pool, failing readiness probes will lead to Pods not receiving any load for a period or time, and with failing liveness probes the Pods will eventually be restarted.
So the best way to run Keycloak in Kubernetes would be to disable those probes, for now. https://github.com/keycloak/keycloak/issues/22109

== Optional: Enable load shedding

== Optional: Disable sticky sessions

We could disable the sticky sessions on the Keycloak Ingress resource in the Kubernetes environment, this would be particularly useful in a use case when running load tests, to avoid receiving all requests on a single Keycloak Pod. One way to implement this is using a below supplementary configuration under the `spec` in  the Keycloak Helm chart.

[source,yaml]
----
spec:
    ingress:
    enabled: true
    annotations:
      # When running load tests, disable sticky sessions on the OpenShift HAProxy router
      # to avoid receiving all requests on a single Keycloak Pod.
      haproxy.router.openshift.io/balance: roundrobin
      haproxy.router.openshift.io/disable_cookies: 'true'
----
