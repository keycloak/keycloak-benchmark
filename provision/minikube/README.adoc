= Provision Keycloak for a benchmark test with minikube
:experimental:
:icons: font

== About

This describes how to install Keycloak and a Grafana/Prometheus/Jaeger monitoring stack.

This uses minikube to run the containers, and Helm to provision the containers.
Keycloak itself is provisioned using the Java based Keycloak operator.
Kubectl is used to interact with minikube on the command line.
https://github.com/astefanutti/kubebox[Kubebox] is installed for a minimal UI to inspect containers within minikube.

The helm charts for Keycloak can be configured to just deploy Kubernetes without the dependency on the PodMonitor and ServiceMonitor dependencies.

This setup has an optional OpenTelemetry (OTEL) setup that will gather additional metrics and will publish traces from within Keycloak to Jaeger service.
This allows measuring the latency per endpoint, and tracing of the database statements executed by a given REST endpoint.
It also collects the logs of all containers inside Loki that can be queried from Grafana.

== Alternatives considered

This paragraph describes some possible alternatives and how they differ from the current approach:

Docker Compose::
+
--
* This setup would have been more minimal, as it wouldn't require a virtual machine for its setup.

* Docker Compose would support CPU limits when running real Docker, but not Podman.

* Docker Compose doesn't support templating so customizing different setups with different CPU limits is difficult while such templating is available with Helm for Minikube.
For the Grafana stack there is a good customizable Helm template with no such way for Docker Compose.
--
+
*Decision:* Go with Minikube, while still keeping Docker Compose as a minimal setup for ad-hoc testing and to allow for a small effort solution for the community.
(Proposed by Alexander Schwartz in May 2022)
+
*Scope:* Docker Compose will contain only Keycloak and a database, and will not contain a monitoring stack, and will not impose any CPU limits.

OpenShift Local (formerly known as CodeReady Containers)::
+
--
* It would have the same capabilities as Minishift, with operator support already installed.
It could be setup automatically (if the developer registers for a Red Hat account and would get a pull secret).

* OpenShift style Monitoring could be installed either via the standard monitoring functionality/operators, and possibly with additional extensions.
On the other hand, the helm charts seem to be more configurable than the OpenShift operator.

* The team of the Keycloak Java operator is working with Minikube to test it, and the operator hub functionality can be installed within minutes with a shell script.
This would allow for running the Keycloak operator on Minishift for this setup as well.

* OpenShift Local will always use a VM, and will be more heavyweight in terms of CPU and RAM usage.
Installing OpenShift is a bigger step for a community contributor.
In the long term, maintaining the setup for both OpenShift and Minikube might be a higher maintenance cost.
Installing OpenShift Local from scratch takes a lot longer than installing Minishift, as OpenShift comes with a lot more Operators that need to download and start their containers and will wait for dependencies.

* Minikube has a mechanism to build containers in a lightweight way locally and provide them to the running Minikube instance.
The alternative for OpenShift would be https://docs.openshift.com/container-platform/4.10/cicd/builds/creating-build-inputs.html#builds-binary-source_creating-build-inputs[binary builds].
--
+
*Decision:* Go with Minikube for now.
Add additional parameterization to the Helm scripts later where needed to deploy on OpenShift (either Local or regular).
Revisit the decision later once the first OpenShift deployments have been made.
(Proposed by Alexander Schwartz in May 2022)

== Present and future

This has been set up for a local developer setup.
Kubebox, Prometheus and Grafana don't require authentication, therefore it shouldn't be installed in an environment that is accessible from remote.

This project should eventually evolve to a setup with multiple namespaces to represent different datacenters.

== Limitations

=== Minikube driver

For Linux, the kvm2 driver is needed for a scalable solution (tested 15 Keycloak replicas).
More instances are possible when adding more than 8 GB of RAM.

The podman driver on Linux currently supports at the moment only up to 5 instances of Keycloak due to the number of open files limit that is actually a limit of the number of threads.
After that, the containers will complain that they're unable to start more processes.

=== Minikube runtime

When testing the cri-o runtime on a bigger machine, https://github.com/keycloak/keycloak-benchmark/issues/128[starting pods and accessing them via the Kubernetes API and via the web browser was flaky].
Pods`' liveness probes were failing now and then, and pods restarted.
After some analysis, the reason was still unclear, it might have been related to the limited number of open files.

=== Minikube persistent store

The PVCs in Minikube will be mounted from the local filesystem.
Due to that, the PVC sizes will not be checked and one service might fill the disk so much that it becomes unavailable for everyone else as well.

=== Jaeger and sampling of tracing

The data collected for each trace are large and can lead to a fast out-of-memory situation with the Jaeger pod.
To minimize the amount of data collected, the value `OTEL_TRACES_SAMPLER_ARG` is set a 0.001 to trace only on out of a thousand requests.
Tracing is disabled by default and can be enabled in Keycloak's helm chart's `values.yaml` file.

As an alternative tracing solution, Tempo was considered.
While traces are submitted via OTEL successfully and the search by trace ID works as expected, the search for traces (currently beta) doesn't return some traces (for example deletion of users).
Therefore, for now, Jaeger tracing is used.

=== Cryostat for JFR recordings

The contents of the helm chart have been created originally by the Cryostat operator.
When analyzing the resources created by the operator in version 2.0, there was no supported way to add the environment variables needed to the cryostat-deployment discovered.
Due to that, this has now been extracted and placed here as a Helm chart.

The Cryostat instance needs to run in the same namespace as the JVMs it connects to.
Due to that, it is part of the Keycloak deployment, and not a separate Helm chart.

The profiling created is regular profiling, not async profiling. The profiling will therefore suffer from the safepoint bias problem. See the https://github.com/jvm-profiling-tools/async-profiler#async-profiler[Java async profiler] for details:

[quote, Java async profiler]
____
This project is a low overhead sampling profiler for Java that does not suffer from Safepoint bias problem.
It features HotSpot-specific APIs to collect stack traces and to track memory allocations.
The profiler works with OpenJDK, Oracle JDK and other Java runtimes based on the HotSpot JVM.
____

For now, not using async profiling should be good enough until proven otherwise.

== Architecture

This describes the runtime view of the setup:

.Minikube runtime view
image::minikube-runtime-view.dio.svg[]

The setup is as follows:

* https://minikube.sigs.k8s.io/[Minikube] runs a virtual machine.
* Via a configured ingress, a local browser can access different services running in Minikube like Keycloak and Grafana.
* https://www.keycloak.org/[Keycloak] connects to a PostgreSQL database running inside Minikube.
* https://www.postgresql.org/[The PostgreSQL database] inside minikube is accessible via a node port from the host.
* https://prometheus.io/[Prometheus] collects metrics, and Jaeger collects traces.
* https://grafana.com/docs/loki/latest/clients/promtail/[Promtail] collects logs and sends it to Loki which stores them.
* https://gatling.io/[Gatling] can run locally and send Graphite metrics via a node port to a collector inside Minikube.
* https://www.jaegertracing.io/[Jaeger] collects traces from Keycloak running inside Minikube, and can also receive traces from a locally running test application.
* https://cryostat.io/[Cryostat] can connect to Keycloak instances and create Java Flight Recorder (JFR) recordings.

Logs, traces and metrics are stored within Minikube for 7 days = 168 hours.
This can be overwritten by adding in an `.env` file with the setting `KB_RETENTION=XXh` to change it to a different value.
Currently, Jaeger requires this to be set in hours, as it doesn't understand this to be set in days.

== Prerequisites

The following needs to be installed on the local machine:

* https://minikube.sigs.k8s.io/docs/start/[Minikube]
* https://helm.sh/docs/intro/install/[Helm]
* https://kubernetes.io/docs/tasks/tools/[kubectl]
* https://taskfile.dev/installation/#get-the-binary[task]
* https://github.com/mikefarah/yq/#install[yq]

The installation can be performed on Linux as follows:

. Download each executable and place it in ~/bin
. Add the following snippet to ~/.bashrc to allow auto-completion of commands
+
----
source <(minikube completion bash)
source <(helm completion bash)
source <(kubectl completion bash)
source <(yq shell-completion bash)
----

////
Not needed for kvm2 driver

Increase the number of files by adding the following to `/etc/systemd/system.conf` and `/etc/systemd/user.conf`:

----
DefaultLimitNOFILE=102400:524288
----

Test the settings afterwards using `ulimit -n`, it should match the first value.

WARNING: There still seems to eb a limit of around ~2k container threads in total that prevents more than 5 running instances of Keycloak.
////

== Installation

=== For the impatient

The installation has been scripted in `rebuild.sh`.
If an existing minikube instance exists, it will destroy it first.
Run this script, and see the URLs printed in the console to access the different services.

Wait a bit for all containers to be pulled from the internet, then get started.

The following commands helps to watch the pods being started, use kbd:[Ctrl+C] to end watching.

[source,shell]
----
kubectl get pods -A -w
----

The following script will check if all services are running and will output a list of available URLs.

[source,shell]
----
./isup.sh
----

To update an existing Minikube setup created with an earlier version of this project, use `upgrade.sh`.
It will install all changes in the Helm charts and Grafana charts.

To open a dashboard showing all Kubernetes resources, run the following command:

[source,shell]
----
minikube dashboard
----

This should open the URL in your default browser.
If it doesn't open it automatically, click on the link it prints on the console.

Then, select a namespace in the header (for example `keycloak`) and browse the resources available in that namespace.

=== For more insights and backgrounds

This section will show the different steps with variants, explain them a bit more.
It also shows the `helm upgrade` commands that can update parts of the stack incrementally which helps development and upgrades.

Startup Minikube in default mode with a VM.
Per default, it will use 2 CPUs, and this can be adjusted

[source,shell]
----
minikube start
----

Start with customized settings.

[source,shell]
----
minikube stop
minikube delete
minikube start --memory 8192 --cpus 4
----

Depending on the driver, adjusting the settings might work for an already created minikube instance.

[source,shell]
----
minikube stop
minikube config set memory 8192
minikube config set cpus 4
minikube start
----

Startup Minikube on Linux w/ podman driver.
This allows faster startup times, less overhead, and no limitation (?) on CPU usage.

////
Installation of cri-o not needed, cri-o will run inside the minikube podman?
dnf module enable cri-o:1.19
dnf install cri-o
////

[source,shell]
----
minikube start --driver=kvm2 --container-runtime=cri-o --docker-opt="default-ulimit=nofile=102400:102400"
----

This requires libvirtd to run.

[source,bash]
----
sudo systemctl enable libvirtd
sudo systemctl start libvirtd
sudo usermod -a -G libvirt $USER
# now relogin, for usermod to become effective
----

For a lightweight installation that today doesn't scale beyond 3-5 Keycloak instances:

[source,shell]
----
minikube start --driver=podman --container-runtime=cri-o
----

On Linux, allow to use podman and crio via sudo:

. run `sudo visudo`
. add the following to the sudoer's file
+
----
username ALL=(ALL) NOPASSWD: /usr/bin/podman
username ALL=(ALL) NOPASSWD: /usr/bin/crictl
----

Adding ingress

[source,shell]
----
minikube addons enable ingress
----

All other installations are scripted using `task`.
It will run all tasks in the correct order and in parallel when possible.
If a task definition changes, it will run it again.
Use `task -f` to force running all tasks again, for example after you've reset minikube.

== Automation using the tool _task_

There are several dependencies that need to be built and executed in the right order.
To simplify upgrades and fast iterations during development, all steps and dependencies have been scripted using https://taskfile.dev/installation/#get-the-binary[_task_].
Think of this tool as a modern version of _make_ that allows simple check-summing of input files and parallel execution of tasks.

All tasks are described in the `Taskfile.yaml` file.
If one of the commands in a task fails, the whole task will fail.
If there are parallel tasks running and one of the tasks fails, _task_ will kill the other tasks running in parallel.

For environment-specific settings, add a `.env` file with the contents necessary for your environment.

The following list shows some command line examples:

`task`::
Executes the `default` task, which will update the minikube installation with the latest changes.
Run it after every local change to a file, or after pulling changes from upstream via git.

`task -f`::
Executes the `default` task, but execute all tasks event if no source file has been changed.
Run it after minikube has been re-created.

`task <taskname>`::
Execute a specific task from the `Taskfile.yaml`.
Most tasks are set up to run only when modified, so task might reply with `task: Task "<taskname>" is up to date`.
To force execution of a task, add the `-f` flag.
This will then execute both the task and its dependencies.

`task <var>=<value>`::
Set a variable with a specific value, then run the task.
Use it for example to set the storage type in a one-off run: `task KC_STORAGE=jpa`.

`task --dry`::
Show which tasks would be executed.
Run it to see what commands _task_ would execute on the next run.
Can be combined with a task name and the `-f` flag.

`task -C 1`::
Start in single-threaded mode, which might help analyzing problems, as the output won't be mixed.
Use this option to debugging task descriptions.
Can be combined with a task name.
+
[WARNING]
====
There seems to be an open bug that can lead to deadlocks, see https://github.com/go-task/task/issues/715[go-task/task#715].

Until this has been fixed, whenever running with the parameter `-C 1`, comment out all `run: once` and `run: when_changed` within the task file.
Previous attempts to remove those statements temporarily lead to problems as those tasks were executed multiple times in parallel.
====

`task -h`::
Start in single-threaded mode, which might help analyzing problems, as the output won't be mixed.
Use this option to find out more about task.
Can be combined with a task name.

Find out more about this tool on its homepage that includes its manual: https://taskfile.dev/

=== Analyzing a failed _task_ run

To analyze a failed run, proceed as follows:

. Identify the failed task by looking at the last line
. Scroll upwards to find the last executed command of that task and the output of that command.

Example output that failed when executing a `kubectl` command in the `keycloak` task:

[source,subs="+quotes"]
----
task: **[keycloak]** kubectl create namespace keycloak || true
**[keycloak]** The connection to the server localhost:8080 was refused - did you specify the right host or port?
task: **[keycloak]** kubectl -n keycloak apply ...
**[keycloak]** The connection to the server localhost:8080 was refused - did you specify the right host or port?
[tlsdisableagent] [INFO] Scanning for projects...
[tlsdisableagent] [INFO]
[tlsdisableagent] [INFO] ------------...
...
task: Failed to run task "**keycloak**": exit status 1
----

== Adding custom dashboards

Login to Grafana with admin / keycloak when anonymous login is not sufficient.

Custom dashboards are included in folder `monitoring/dashbaords`.
Add more dashboards there as new files, and `task` will install the latest versions in the minikube cluster.

== Customizing Keycloak

Keycloak is installed with monitoring enabled.

Add local customizations via `keycloak/values.yaml`:

* Set `monitoring` to `false` to install Keycloak without monitoring options.

* Set `otel` to `true` to install Keycloak with opentelemetry enabled.

== Pause/Resume setup

The setup can be paused and resumed without restarting/reinstalling all pods.

To stop, run the following command:

[source,bash]
----
minikube stop
----

To resume, run the following command.

[source,bash]
----
minikube start
----

After minikube has been re-started, it might have a different IP address for the ingress.
Due to that, all ingresses need to be updated.
Do this, run `task`.

== Reset the system under test aka Keycloak

This will clear the database and restart the Keycloak instance.
Once that is complete, it re-initializes the user for Gatling.

[source,bash]
----
task reset-keycloak
----

== Deploying providers to Minikube

Keycloak be extended by providers.
This is also supported in this setup.

All providers JARs need to be placed in `keycloak/providers`.

After updating the files there, run `task`.
Keycloak will restart and the providers will then be available.
https://kubernetes.io/docs/concepts/configuration/configmap/#motivation[As this uses a ConfigMap to place all information Kubernetes, the combined size of all providers encoded as base64 is 1 MiB].

The dataprovider module is deployed by default.

To test if the dataprovider module has been deployed, test the URL \https://keycloak.xx.xx.xx.xx.nip.io/realms/master/dataset/status.
Use the `./isup.sh` script to find out about the IP address of Keycloak.

== Running `kcadm.sh` with invalid TLS certificates

The minikube setup doesn't contain trusted TLS certificates, and the certificates will also not match the hostnames.

To disable the TLS checks in Java, see the module `provision/tlsdisableagent` for details on how to run for example `kcadm.sh`.

== Accessing the PostgreSQL database inside minikube

To access the PostgreSQL database running inside minikube, there are the following options:

* Execute a shell using `kubectl`:
+
----
kubectl exec `kubectl get pods --selector=app=postgres -n keycloak -o name` -n keycloak -it -- psql --user keycloak
----

* Open the web-based sqlpad pod. Run the `isup.sh` shell script to see the URL. +
Log in with username `admin` and password `admin`.

* Connect via a local DB client:
+
--
. Retrieve minikube's IP address using `minikube ip`
. Assuming that the IP-address is `192.168.39.39`, point your DB tool at the JDBC URL `jdbc:postgresql://192.168.39.39:30009/keycloak`.
+
The connection details: Port will always be `30009`, username is `keycloak`, password is `pass`, database name is `keycloak`.
--
+
NOTE: Minikube's IP address will change every time you re-create the minikube instance.

== Accessing the CockroachDB inside minikube

CockroachDB is a store available for the JPA map storage.
It can be enabled via the following settings in the `.env` file:

[source]
----
KC_DATABASE=cockroach
KC_STORAGE=jpa
----

Once these settings have been deployed using `task`, the DB console is available at \https://cockroach.<minikube ip>.

Like the PostgreSQL database, it is also available in SQLPad.
To access it from the local machine with an IDE or database tool, use the same configuration as for PostgreSQL and exchange the port `30009` with `30010`.

== Metrics from the PostgresSQL database

There is an instance of https://github.com/prometheus-community/postgres_exporter[postgres_exporter] running in minikube and its metrics are collected in Prometheus.

Additional SQL query for metrics can be defined in `pgexporter-queries.yaml`.

== Creating a Java Flight Recorder recording

* Open the Cryostat instance's website. Run the `isup.sh` shell script to see the URL.
* Click on the menu item menu:Recordings[].
* Select a target VM.
* Click on button btn:[Create] to create a new recording and follow the dialogs.

Once the recording is complete, download it directly or archive it to the persistent volume of Cryostat to download it later.

== Running Gatling

To run the benchmarks using Gatling on your local machine and to forward the metrics to the Graphite exporter in Minikube, you'll need to pass the IP-address of Minikube as an environment variable that is then used inside `gatling.conf`.

[source,bash]
----
export GRAPHITE_TCP_ADDR=$(minikube ip)
----

The mapping of Gatling's metrics to Prometheus a metric name and labels is configured in `graphite_mapping.yaml`.
Once the test runs, the metrics are available as `gatling_users` and `gatling_requests`.

This setup assumes that only one load driver is running.
If more load drivers are running, change the `rootPathPrefix` in Gatling's configuration and the `gatling.conf` setup need to change.
For now, this is considered out-of-scope as one Gatling instance can generate several orders of magnitude more load than needed.

The Prometheus Gatling exporter will hold the metrics for 5 minutes and then forget them.
By that time, Prometheus will have already scraped them and stored the values in its database.

== Connecting to a remote host running minikube

When running minikube on a remote host, the ports will not be accessible remotely from the outside of the host.
If they would, this would be a security concern due to the default passwords and sometimes no password being used on the applications deployed on minikube and the Kubernetes API itself.

To connect to Keycloak and other services remotely, one way is to use SSH port forwarding.

As Keycloak is quick specific about the configured port and IP address, the port forwarding needs to bind the same port as on minikube.
As it is running on minikube with port 443, this requires running ssh as root so that it can bind port 443 locally.

Given the IP address of minikube on the remote host retrieved by `mininkube ip` with content of `192.168.39.19` the following steps work.

[NOTE]
====
Whenever the minikube instance on the remote host is re-created, it will receive a different IP address and the commands need to be adjusted.
====

. Add an entry to the local `hosts` file that points the host names of minikube:
+
----
127.0.0.1 kubebox.192.168.39.19.nip.io grafana.192.168.39.19.nip.io keycloak.192.168.39.19.nip.io
----

. Put the current user's ssh keys in for the root user, so that `sudo ssh` has access to them.

. Run ssh with port forwarding:
+
----
sudo ssh -L 443:192.168.39.19:443 user@remotehost
----

Now point the browser to \https://keycloak.192.168.39.19.nip.io as usual to interact with the application.
With the SSH tunnel in place, the response times are a bit slower, so users will not be able to run a representative load test with gatling on their local machine and minikube running on the remote machine.

To optimize the server side of the connection, consider updating the `MaxSessions` parameter in sshd, as otherwise the number sessions via one SSH session would be restricted to 10, and users might see a blocking browser.
A recommended number would be 100.