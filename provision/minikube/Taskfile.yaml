# https://taskfile.dev

version: '3'

output: prefixed

vars:
  IP:
    sh: minikube ip
  KB_RETENTION: '{{default "168h" .KB_RETENTION}}'
  KC_DB_POOL_INITIAL_SIZE: '{{default "5" .KC_DB_POOL_INITIAL_SIZE}}'
  KC_DB_POOL_MAX_SIZE: '{{default "10" .KC_DB_POOL_MAX_SIZE}}'
  KC_DB_POOL_MIN_SIZE: '{{default "5" .KC_DB_POOL_MIN_SIZE}}'
  KC_STORAGE: '{{default "" .KC_STORAGE}}'
  KC_DATABASE: '{{default "postgres" .KC_DATABASE}}'
  KC_CONTAINER_IMAGE: '{{default "" .KC_CONTAINER_IMAGE}}'

dotenv: ['.env']

tasks:
  default:
    deps:
      - gatlinguser
    cmds:
      - echo Keycloak is ready for load testing!
      - bash -c ./isup.sh
    silent: true

  ipchange:
    deps:
      - split
    cmds:
      - rm -f .task/checksum/keycloak
      - rm -f .task/checksum/prometheus
      - rm -f .task/checksum/monitoring
      - mkdir -p .task
      - echo -n {{.IP}} > .task/status-{{.TASK}}
    sources:
      - .task/subtask-{{.TASK}}.yaml
    status:
      - test -e .task/status-{{.TASK}}
      - test "{{.IP}}" == "$(cat .task/status-{{.TASK}})"
    # avoid 'once' until https://github.com/go-task/task/issues/715 when running with parameter '-C 1'
    run: once

  reset-keycloak:
    deps:
      - split
    cmds:
      - bash -c "kubectl delete deployment/{{.KC_DATABASE}} -n keycloak || exit 0"
      - >
        bash -c '
        if [ "{{.KC_DATABASE}}" == "cockroach-single" ];
        then kubectl delete deployment/cockroach -n keycloak || exit 0;
        fi'
      - bash -c "kubectl delete keycloak/keycloak -n keycloak || exit 0"
      - bash -c "kubectl delete deployment/keycloak-operator -n keycloak || exit 0"
      - ./init-database.sh {{.KC_DATABASE}} reset
      # discard status of keycloak to force redeployment
      - rm -f .task/checksum/keycloak
      # discard status of gatling user to force redeployment
      - rm -f .task/checksum/gatlinguser
      - task: default

  split:
    desc: Split Taskfile to one-file-per-task for dirty checking
    # avoid 'once' until https://github.com/go-task/task/issues/715 when running with parameter '-C 1'
    run: once
    cmds:
      - bash -c ./split.sh
    sources:
      - Taskfile.yaml
      - split.sh
    silent: true

  env:
    cmds:
      # create marker files that can then be checked in other tasks
      - mkdir -p .task
      - echo {{.KB_RETENTION}} > .task/var-KB_RETENTION
      - echo {{.KC_DB_POOL_INITIAL_SIZE}} > .task/var-KC_DB_POOL_INITIAL_SIZE
      - echo {{.KC_DB_POOL_MAX_SIZE}} > .task/var-KC_DB_POOL_MAX_SIZE
      - echo {{.KC_DB_POOL_MIN_SIZE}} > .task/var-KC_DB_POOL_MIN_SIZE
      - echo {{.KC_CONTAINER_IMAGE}} > .task/var-KC_CONTAINER_IMAGE
      - echo {{.KC_STORAGE}} > .task/var-KC_STORAGE
      - echo {{.KC_DATABASE}} > .task/var-KC_DATABASE
    run: once
    sources:
      - .task/subtask-{{.TASK}}.yaml
    status:
      - test "{{.KB_RETENTION}}" == "$(cat .task/var-KB_RETENTION)"
      - test "{{.KC_DB_POOL_INITIAL_SIZE}}" == "$(cat .task/var-KC_DB_POOL_INITIAL_SIZE)"
      - test "{{.KC_DB_POOL_MAX_SIZE}}" == "$(cat .task/var-KC_DB_POOL_MAX_SIZE)"
      - test "{{.KC_DB_POOL_MIN_SIZE}}" == "$(cat .task/var-KC_DB_POOL_MIN_SIZE)"
      - test "{{.KC_STORAGE}}" == "$(cat .task/var-KC_STORAGE)"
      - test "{{.KC_DATABASE}}" == "$(cat .task/var-KC_DATABASE)"
      - test "{{.KC_CONTAINER_IMAGE}}" == "$(cat .task/var-KC_CONTAINER_IMAGE)"

  prometheus:
    deps:
      - split
      - ipchange
      - env
    cmds:
      - kubectl create namespace monitoring || true
      - helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
      - helm repo update
      - helm upgrade --install prometheus prometheus-community/kube-prometheus-stack --version 39.11.0 -f monitoring.yaml --set grafana."grafana\.ini".server.root_url=https://grafana.{{.IP}}.nip.io --set prometheus.prometheusSpec.retention={{.KB_RETENTION}}
    sources:
      - monitoring.yaml
      - .task/subtask-{{.TASK}}.yaml
      - .task/var-KB_RETENTION
    run: once

  monitoring:
    deps:
      - prometheus
      - split
      - ipchange
    cmds:
      - helm upgrade --install monitoring --set hostname={{.IP}}.nip.io monitoring
    sources:
      - monitoring/**/*.*
      - .task/subtask-{{.TASK}}.yaml

  jaeger:
    deps:
      - split
      - prometheus
      - env
    env:
      KB_RETENTION: '{{.KB_RETENTION}}'
    cmds:
      - helm repo add jaegertracing https://jaegertracing.github.io/helm-charts
      - helm repo update
      - helm upgrade --install jaeger jaegertracing/jaeger --version 0.58.0 -n monitoring -f jaeger/values.yaml
      - envsubst < jaeger/deployment-patch.yaml > .task/subtask-{{.TASK}}-patchfile.yaml
      - echo $KB_RETENTION
      - kubectl patch deployment jaeger -n monitoring --patch-file .task/subtask-{{.TASK}}-patchfile.yaml
    sources:
      - jaeger/**/*.*
      - .task/subtask-{{.TASK}}.yaml
      - .task/var-KB_RETENTION

  tempo:
    deps:
      - split
      - prometheus
    cmds:
      # For now, Jaeger stores the traces, and Tempo is disabled.
      # - helm repo add grafana https://grafana.github.io/helm-charts
      # - helm repo update
      # - helm upgrade --install tempo grafana/tempo -n monitoring -f tempo.yaml
      - helm delete tempo -n monitoring || exit 0
    sources:
      - tempo.yaml
      - .task/subtask-{{.TASK}}.yaml

  loki:
    deps:
      - split
      - env
      - prometheus
    cmds:
      - helm repo add grafana https://grafana.github.io/helm-charts
      - helm repo update
      # A loki update might fail as a stateful set can't be updated. If that fails, uninstall and re-install.
      - >
        bash -c "helm upgrade --install loki grafana/loki --version 3.0.0 -n monitoring -f loki.yaml --set config.table_manager.retention_period={{.KB_RETENTION}}
        || (helm delete loki -n monitoring && helm upgrade --install loki grafana/loki --version 3.0.0 -n monitoring -f loki.yaml --set config.table_manager.retention_period={{.KB_RETENTION}})"
    sources:
      - loki.yaml
      - .task/subtask-{{.TASK}}.yaml
      - .task/var-KB_RETENTION

  promtail:
    deps:
      - split
      - prometheus
    cmds:
      - helm repo add grafana https://grafana.github.io/helm-charts
      - helm repo update
      - helm upgrade --install promtail grafana/promtail --version 6.3.0 -n monitoring -f promtail.yaml
    sources:
      - promtail.yaml
      - .task/subtask-{{.TASK}}.yaml

  mvnw:
    dir: ../..
    run: once
    cmds:
      # download maven wrapper to avoid concurrent downloads with can break the build
      - ./mvnw -v
    sources:
      - ../../.mvn/wrapper/maven-wrapper.properties
      - .task/subtask-{{.TASK}}.yaml
    generates:
      - ../../.mvn/wrapper/maven-wrapper.jar

  dataset:
    deps:
      - split
      - mvnw
    dir: ../..
    cmds:
      - ./mvnw -B -am -pl dataset clean install -DskipTests
    sources:
      - ../../pom.xml
      - dataset/pom.xml
      - dataset/src/**/*.*
      - .task/subtask-{{.TASK}}.yaml
    generates:
      - dataset/target/keycloak-benchmark-dataset-*.jar

  datasetprovider:
    deps:
      - dataset
      - split
    cmds:
      - mkdir -p keycloak/providers
      - rm -f keycloak/providers/keycloak-benchmark-dataset-*.jar
      - cp ../../dataset/target/keycloak-benchmark-dataset-*.jar keycloak/providers
    sources:
      - ../../dataset/target/keycloak-benchmark-dataset-*.jar
      - .task/subtask-{{.TASK}}.yaml
    status:
      - test -f keycloak/providers/keycloak-benchmark-dataset-*.jar

  dataset-import:
    deps:
      - gatlinguser
    cmds:
      - bash -c "../../dataset/dataset-import.sh {{.CLI_ARGS}}"
    silent: true

  tlsdisableagent:
    deps:
      - split
      - mvnw
    dir: ../tlsdisableagent
    cmds:
      - bash -c ./buildtlsagent.sh
    sources:
      - ../tlsdisableagent/hooks/*.*
      - ../tlsdisableagent/buildtlsagent.sh
      - ../tlsdisableagent/tlscheckdisable.txt
      - ../tlsdisableagent/java-instrumentation-tool/src/**/*.*
      - ../tlsdisableagent/java-instrumentation-tool/pom.xml
      - .task/subtask-{{.TASK}}.yaml
    generates:
      - ../tlsdisableagent/tlscheckdisable-agent.jar

  keycloak-cli-download:
    dir: ..
    cmds:
      - mkdir -p keycloak-cli
      - rm -f keycloak-cli/*.zip
      # if the nightly release doesn't exist, download a specific release as a fallback
      # revisit once https://github.com/keycloak-rel/keycloak-rel/issues/47 as been fixed
      - >
        curl -L -f https://github.com/keycloak/keycloak/releases/download/nightly/keycloak-999-SNAPSHOT.zip -o keycloak-cli/keycloak.zip ||
        curl -L -f https://github.com/keycloak/keycloak/releases/download/19.0.1/keycloak-19.0.1.zip -o keycloak-cli/keycloak.zip
    status:
      - test -f keycloak-cli/keycloak.zip
    sources:
      - .task/subtask-{{.TASK}}.yaml

  keycloak-cli-unzip:
    deps:
      - keycloak-cli-download
      - split
    dir: ..
    cmds:
      # remove temporary folders to be extra safe
      - rm -rf keycloak-cli/keycloak-999-SNAPSHOT keycloak-cli/keycloak-19.0.1
      - rm -rf keycloak-cli/keycloak
      - unzip -o -q keycloak-cli/keycloak.zip -d keycloak-cli
      # the output folder depends on the version we're about to unpack
      - mv keycloak-cli/keycloak-999-SNAPSHOT keycloak-cli/keycloak || mv keycloak-cli/keycloak-19.0.1 keycloak-cli/keycloak
    sources:
      - keycloak-cli/keycloak.zip
      - minikube/.task/subtask-{{.TASK}}.yaml

  gatlinguser:
    deps:
      - keycloak-cli-unzip
      - tlsdisableagent
      - keycloak
      - split
      - ipchange
    env:
      KC_OPTS: "-javaagent:../tlsdisableagent/tlscheckdisable-agent.jar"
      KEYCLOAK_HOME: "../keycloak-cli/keycloak"
    cmds:
      - bash -c ./isup.sh
      - bash -c "../keycloak-cli/keycloak/bin/kcadm.sh config credentials --server https://keycloak.{{.IP}}.nip.io/ --realm master --user admin --password admin"
      - bash -c "../../benchmark/src/main/content/bin/initialize-benchmark-entities.sh -r test-realm -d"
    sources:
      - ../../benchmark/src/main/content/bin/initialize-benchmark-entities.sh
      - .task/subtask-{{.TASK}}.yaml
      # if keycloak's database deployment changes, this restarts the DB and the Gatling user needs to be re-created
      - .task/status-keycloak-db.json
      - .task/var-KC_STORAGE
      - .task/var-KC_DATABASE

  keycloak:
    deps:
      - monitoring
      - datasetprovider
      - split
      - ipchange
      - jaeger
      - loki
      - tempo
      - promtail
      - env
    cmds:
      - kubectl create namespace keycloak || true
      - kubectl -n keycloak apply -f https://raw.githubusercontent.com/keycloak/keycloak-k8s-resources/refs/tags/nightly/kubernetes/keycloaks.k8s.keycloak.org-v1.yml
      - kubectl -n keycloak apply -f https://raw.githubusercontent.com/keycloak/keycloak-k8s-resources/refs/tags/nightly/kubernetes/keycloakrealmimports.k8s.keycloak.org-v1.yml
      - kubectl -n keycloak apply -f https://raw.githubusercontent.com/keycloak/keycloak-k8s-resources/refs/tags/nightly/kubernetes/kubernetes.yml || (kubectl -n keycloak delete deployment/keycloak-operator && kubectl -n keycloak apply -f https://raw.githubusercontent.com/keycloak/keycloak-k8s-resources/refs/tags/nightly/kubernetes/kubernetes.yml)
      - >
        bash -c '
        if [ "{{.KC_CONTAINER_IMAGE}}" != "" ]; then
          envsubst < keycloak/operator-patch.yaml > .task/subtask-{{.TASK}}-operator-patchfile.yaml
          kubectl patch deployment keycloak-operator -n keycloak --patch-file .task/subtask-{{.TASK}}-operator-patchfile.yaml
        fi'
      - >
        helm upgrade --install keycloak
        --set hostname={{.IP}}.nip.io
        --set dbPoolInitialSize={{.KC_DB_POOL_INITIAL_SIZE}}
        --set dbPoolMinSize={{.KC_DB_POOL_MIN_SIZE}}
        --set dbPoolMaxSize={{.KC_DB_POOL_MAX_SIZE}}
        --set storage={{.KC_STORAGE}}
        --set database={{.KC_DATABASE}}
        --set keycloakImage={{.KC_CONTAINER_IMAGE}}
        keycloak
      - >
        bash -c '
        if [ "{{.KC_DATABASE}}" == "cockroach-operator" ];
        then kubectl -n keycloak -o yaml get crdbclusters.crdb.cockroachlabs.com/cockroach > .task/status-{{.TASK}}-db.json;
        elif [ "{{.KC_DATABASE}}" == "cockroach-single" ];
        then kubectl get deployment/cockroach -n keycloak -o=jsonpath="{.spec}" > .task/status-{{.TASK}}-db.json;
        elif [ "{{.KC_DATABASE}}" != "none" ];
        then kubectl get deployment/{{.KC_DATABASE}} -n keycloak -o=jsonpath="{.spec}" > .task/status-{{.TASK}}-db.json;
        else echo "none" > .task/status-{{.TASK}}-db.json;
        fi'
      # kill all CrashLoopBackOff and ImagePullBackOff pods to trigger a fast restart and not wait Kubernetes
      - bash -c 'kubectl get pods -A | grep -E "(BackOff|Error|ErrImageNeverPull|InvalidImageName)" | tr -s " " | cut -d" " -f1-2 | xargs -r -L 1 kubectl delete pod -n'
      # wait a bit for the operator to pick up the changes
      - bash -c 'sleep 1'
      - ./init-database.sh {{.KC_DATABASE}}
      - ./isup.sh
      # remove all no longer used images from minikube to preserve disk space
      - minikube ssh -- docker container prune -f
      - minikube ssh -- docker image prune -f
      - minikube ssh -- docker volume prune -f
    sources:
      - keycloak/**/*.*
      - .task/subtask-{{.TASK}}.yaml
      - .task/var-KC_*
